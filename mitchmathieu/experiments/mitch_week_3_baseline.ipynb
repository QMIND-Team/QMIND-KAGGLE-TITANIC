{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline at a glance:\n",
    "load data -> cleaning/preprocessing -> feature eng -> format data for modelling -> fit model -> evaluate model -> generate submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../experiments/train.csv')\n",
    "df_test = pd.read_csv('../experiments/test.csv')\n",
    "\n",
    "# for convenience\n",
    "datasets = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "mAge = pd.concat((df_train['Age'], df_test['Age']), axis=0).mean()\n",
    "medFare = pd.concat((df_train['Fare'], df_test['Fare']), axis=0).median()\n",
    "for df in datasets:\n",
    "    df['Age'] = df['Age'].fillna(mAge)\n",
    "    df['Fare'] = df['Fare'].fillna(medFare)\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       7.8958  14.4542  31.275  512.3292]\n"
     ]
    }
   ],
   "source": [
    "# find fare bins based on frequency rather than value\n",
    "garbage, fare_bins = pd.qcut(df_train['Fare'].append(df_test['Fare']), 4, retbins=True)\n",
    "print(fare_bins)\n",
    "# loops through both train and test set for convenience\n",
    "for df in datasets:\n",
    "    # bin age\n",
    "    df['Age_binned'] = pd.cut(df['Age'], [0,16,32,48,64,200], labels = [0,1,2,3,4], retbins=False)\n",
    "    \n",
    "    # bin fare\n",
    "    df['Fare_binned'] = pd.cut(df['Fare'], fare_bins, labels = [0,1,2,3], include_lowest=True, retbins=False)\n",
    "    \n",
    "    # family features\n",
    "    df['Family_size'] = df_train['SibSp'] + df_train['Parch']\n",
    "    df['Is_Alone'] = (df['Family_size'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded rows\n",
    "for df in datasets:\n",
    "    df.drop(['Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "    \n",
    "# need to keep passengerID for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Format data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categoricals using pd.get_dummies\n",
    "df_train = pd.get_dummies(df_train, columns=['Embarked', 'Sex'])\n",
    "df_test = pd.get_dummies(df_test, columns=['Embarked', 'Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y, and select features to use\n",
    "X = df_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = df_train['Survived']\n",
    "X_test = df_test.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data X and y into train and val sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "      X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age_binned     0\n",
       "Fare_binned    0\n",
       "Family_size    0\n",
       "Is_Alone       0\n",
       "Embarked_C     0\n",
       "Embarked_Q     0\n",
       "Embarked_S     0\n",
       "Sex_female     0\n",
       "Sex_male       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train (or fit) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit rf\n",
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit lgbm\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n",
    "\n",
    "lg = lgb.train(params, train_set=d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a scoring function\n",
    "def acc(y: np.array, y_pred: np.array) -> float:\n",
    "    return np.sum(y_pred==y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict on train and val sets\n",
    "y_pred_trn_lr = lr.predict(X_train)\n",
    "y_pred_val_lr = lr.predict(X_val)\n",
    "\n",
    "y_pred_trn_rf = rf.predict(X_train)\n",
    "y_pred_val_rf = rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-89b34731122a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred_val_lg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# setting threshold to .5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_val_lg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_pred_val_lg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m        \u001b[0my_pred_val_lg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# LGBM prediction\n",
    "y_pred_trn_lg = lg.predict(X_train)\n",
    "y_pred_val_lg = lg.predict(X_val)\n",
    "# setting threshold to .5              not working rn\n",
    "size = y_pred_val_lg.size()\n",
    "for i in range(0, size):\n",
    "    if y_pred_val_lg[i]>=.5:       \n",
    "       y_pred_val_lg[i]=1\n",
    "    else:  \n",
    "       y_pred_val_lg[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR train set accuracy 0.800561797752809\n",
      "LR val set accuracy 0.7988826815642458\n",
      "RF train set accuracy 0.8764044943820225\n",
      "RF val set accuracy 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "print('LR train set accuracy', acc(y_train, y_pred_trn_lr))\n",
    "print('LR val set accuracy', acc(y_val, y_pred_val_lr))\n",
    "print('RF train set accuracy', acc(y_train, y_pred_trn_rf))\n",
    "print('RF val set accuracy', acc(y_val, y_pred_val_rf))\n",
    "#print('LGBM train set accuracy', acc(y_train, y_pred_trn_lg))\n",
    "#print('LGBM val set accuracy', acc(y_val, y_pred_val_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test set\n",
    "\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Create a Kaggle submission\n",
    "sub = pd.DataFrame({'PassengerId': df_test['PassengerId'],\n",
    "                    'Survived': y_pred_test})\n",
    "\n",
    "sub.to_csv('week_3_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
