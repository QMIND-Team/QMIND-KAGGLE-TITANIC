{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline at a glance:\n",
    "load data -> cleaning/preprocessing -> feature eng -> format data for modelling -> fit model -> evaluate model -> generate submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# for convenience\n",
    "datasets = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "mAge = pd.concat((df_train['Age'], df_test['Age']), axis=0).mean()\n",
    "medFare = pd.concat((df_train['Fare'], df_test['Fare']), axis=0).median()\n",
    "for df in datasets:\n",
    "    df['Age'] = df['Age'].fillna(mAge)\n",
    "    df['Fare'] = df['Fare'].fillna(medFare)\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       7.8958  14.4542  31.275  512.3292]\n"
     ]
    }
   ],
   "source": [
    "# find fare bins based on frequency rather than value\n",
    "garbage, fare_bins = pd.qcut(df_train['Fare'].append(df_test['Fare']), 4, retbins=True)\n",
    "print(fare_bins)\n",
    "# loops through both train and test set for convenience\n",
    "for df in datasets:\n",
    "    # bin age\n",
    "    df['Age_binned'] = pd.cut(df['Age'], [0,16,32,48,64,200], labels = [0,1,2,3,4], retbins=False)\n",
    "    \n",
    "    # bin fare\n",
    "    df['Fare_binned'] = pd.cut(df['Fare'], fare_bins, labels = [0,1,2,3], include_lowest=True, retbins=False)\n",
    "    \n",
    "    # family features\n",
    "    df['Family_size'] = df_train['SibSp'] + df_train['Parch']\n",
    "    df['Is_Alone'] = (df['Family_size'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded rows\n",
    "for df in datasets:\n",
    "    df.drop(['Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "    \n",
    "# need to keep passengerID for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Format data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categoricals using pd.get_dummies\n",
    "df_train = pd.get_dummies(df_train, columns=['Embarked', 'Sex'])\n",
    "df_test = pd.get_dummies(df_test, columns=['Embarked', 'Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y, and select features to use\n",
    "X = df_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = df_train['Survived']\n",
    "X_test = df_test.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data X and y into train and val sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "      X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age_binned     0\n",
       "Fare_binned    0\n",
       "Family_size    0\n",
       "Is_Alone       0\n",
       "Embarked_C     0\n",
       "Embarked_Q     0\n",
       "Embarked_S     0\n",
       "Sex_female     0\n",
       "Sex_male       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train (or fit) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit rf\n",
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tania\\Documents\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\tania\\Documents\\anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "def run_gridsearch(X_train, y_train, clf, param_grid, cv=5):\n",
    "    grid_search = GridSearchCV(clf,\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv)\n",
    "    start = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print((\"\\nGridSearchCV took {:.2f} \"\n",
    "           \"seconds for {:d} candidate \"\n",
    "           \"parameter settings.\").format(time() - start,\n",
    "                len(grid_search.grid_scores_)))\n",
    "\n",
    "    top_params = report(grid_search.grid_scores_, 3)\n",
    "    return  top_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a scoring function\n",
    "def acc(y: np.array, y_pred: np.array) -> float:\n",
    "    return np.sum(y_pred==y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict on train and val sets\n",
    "y_pred_trn_SVC = clf.predict(X_train)\n",
    "y_pred_val_SVC = clf.predict(X_val)\n",
    "\n",
    "y_pred_trn_rf = rf.predict(X_train)\n",
    "y_pred_val_rf = rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC train set accuracy 0.7879213483146067\n",
      "SVC val set accuracy 0.7821229050279329\n",
      "RF train set accuracy 0.8764044943820225\n",
      "RF val set accuracy 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "print('SVC train set accuracy', acc(y_train, y_pred_trn_SVC))\n",
    "print('SVC val set accuracy', acc(y_val, y_pred_val_SVC))\n",
    "print('RF train set accuracy', acc(y_train, y_pred_trn_rf))\n",
    "print('RF val set accuracy', acc(y_val, y_pred_val_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test set\n",
    "\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Create a Kaggle submission\n",
    "sub = pd.DataFrame({'PassengerId': df_test['PassengerId'],\n",
    "                    'Survived': y_pred_test})\n",
    "\n",
    "sub.to_csv('Experiment2-SVC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
