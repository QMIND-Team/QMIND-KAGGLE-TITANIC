{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tania\\Documents\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline at a glance:\n",
    "load data -> cleaning/preprocessing -> feature eng -> format data for modelling -> fit model -> evaluate model -> generate submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# for convenience\n",
    "datasets = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "mAge = pd.concat((df_train['Age'], df_test['Age']), axis=0).mean()\n",
    "medFare = pd.concat((df_train['Fare'], df_test['Fare']), axis=0).median()\n",
    "for df in datasets:\n",
    "    df['Age'] = df['Age'].fillna(mAge)\n",
    "    df['Fare'] = df['Fare'].fillna(medFare)\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       7.8958  14.4542  31.275  512.3292]\n"
     ]
    }
   ],
   "source": [
    "# find fare bins based on frequency rather than value\n",
    "garbage, fare_bins = pd.qcut(df_train['Fare'].append(df_test['Fare']), 4, retbins=True)\n",
    "print(fare_bins)\n",
    "# loops through both train and test set for convenience\n",
    "for df in datasets:\n",
    "    # bin age\n",
    "    df['Age_binned'] = pd.cut(df['Age'], [0,16,32,48,64,200], labels = [0,1,2,3,4], retbins=False)\n",
    "    \n",
    "    # bin fare\n",
    "    df['Fare_binned'] = pd.cut(df['Fare'], fare_bins, labels = [0,1,2,3], include_lowest=True, retbins=False)\n",
    "    \n",
    "    # family features\n",
    "    df['Family_size'] = df_train['SibSp'] + df_train['Parch']\n",
    "    df['Is_Alone'] = (df['Family_size'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded rows\n",
    "for df in datasets:\n",
    "    df.drop(['Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "    \n",
    "# need to keep passengerID for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Format data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categoricals using pd.get_dummies\n",
    "df_train = pd.get_dummies(df_train, columns=['Embarked', 'Sex'])\n",
    "df_test = pd.get_dummies(df_test, columns=['Embarked', 'Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y, and select features to use\n",
    "X = df_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = df_train['Survived']\n",
    "X_test = df_test.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data X and y into train and val sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "      X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age_binned     0\n",
       "Fare_binned    0\n",
       "Family_size    0\n",
       "Is_Alone       0\n",
       "Embarked_C     0\n",
       "Embarked_Q     0\n",
       "Embarked_S     0\n",
       "Sex_female     0\n",
       "Sex_male       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train (or fit) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(n_neighbors=5)  \n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit rf\n",
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a scoring function\n",
    "def acc(y: np.array, y_pred: np.array) -> float:\n",
    "    return np.sum(y_pred==y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict on train and val sets\n",
    "y_pred_trn_knn = clf.predict(X_train)\n",
    "y_pred_val_knn = clf.predict(X_val)\n",
    "\n",
    "y_pred_trn_rf = rf.predict(X_train)\n",
    "y_pred_val_rf = rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN train set accuracy 0.8441011235955056\n",
      "KNN val set accuracy 0.7932960893854749\n",
      "RF train set accuracy 0.8764044943820225\n",
      "RF val set accuracy 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "print('KNN train set accuracy', acc(y_train, y_pred_trn_knn))\n",
    "print('KNN val set accuracy', acc(y_val, y_pred_val_knn))\n",
    "print('RF train set accuracy', acc(y_train, y_pred_trn_rf))\n",
    "print('RF val set accuracy', acc(y_val, y_pred_val_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test set\n",
    "\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Create a Kaggle submission\n",
    "sub = pd.DataFrame({'PassengerId': df_test['PassengerId'],\n",
    "                    'Survived': y_pred_test})\n",
    "\n",
    "sub.to_csv('week_3_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
